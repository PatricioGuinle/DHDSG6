{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "try:\n",
    "    # settings colab:\n",
    "    import google.colab\n",
    "\n",
    "    ! mkdir -p ../Data\n",
    "    # los que usan colab deben modificar el token de esta url:\n",
    "    ! wget -O ../Data/bikes.csv https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_students_2020/master/M3/CLASE_16_Regresion_Lineal_Multiple/Data/bikes.csv?token=AA4GFHIG665I3BPVQCFY3US63APZM\n",
    "    \n",
    "except ModuleNotFoundError:    \n",
    "    # settings local:\n",
    "    %run \"common/0_notebooks_base_setup.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 880
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 855,
     "status": "error",
     "timestamp": 1546527663689,
     "user": {
      "displayName": "Martín Ríos",
      "photoUrl": "",
      "userId": "02594387867327172413"
     },
     "user_tz": 180
    },
    "id": "3Ad7aOLNyhg6",
    "outputId": "b34ab32d-d009-40f8-f9d3-3ee439dd438a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import sklearn.model_selection as model_selection\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.linear_model as linear_model\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import unicodedata\n",
    "%matplotlib inline\n",
    "\n",
    "# Definimos parámetros globales para matplotlib.\n",
    "plt.rcParams['figure.figsize'] = (10, 8)\n",
    "plt.rcParams['font.size'] = 16\n",
    "\n",
    "data_original = pd.read_csv('Clean08_OultiersxZona_Ale_02.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in data_original.columns[3:]:\n",
    "    if data_original[c].isnull().sum() > 0:\n",
    "        print(c, \" \", data_original[c].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_original.drop(columns=\n",
    "['Unnamed: 0', \n",
    " 'Unnamed: 0.1', \n",
    " 'Unnamed: 0.1.1',\n",
    " 'index',\n",
    " 'operation', \n",
    " 'property_type', \n",
    " 'geonames_id', \n",
    " 'lat-lon',\n",
    " 'price',\n",
    " 'currency',\n",
    " 'country_name',\n",
    " 'price_aprox_local_currency',\n",
    " 'price_aprox_usd',\n",
    " 'price_per_m2',\n",
    " 'floor', \n",
    " 'title', \n",
    " 'image_thumbnail', \n",
    " 'Operacion_Description',\n",
    " 'expenses',\n",
    " 'properati_url',\n",
    " 'Operacion_Title', \n",
    " 'Operacion_URL',\n",
    " 'url_clean',\n",
    " 'url_terraza', \n",
    " 'url_quincho', \n",
    " 'desc_terraza', \n",
    " 'desc_quincho',\n",
    " 'desc_banios',\n",
    " 'tipo_propiedad_Fondo de Comercio', \n",
    " 'Outliers',\n",
    " 'País',\n",
    " 'Provincia', \n",
    " 'Área', \n",
    " 'Localidad', \n",
    " 'Zona', \n",
    " 'Lugar',\n",
    " 'place_with_parent_names', \n",
    " 'lat', 'lon', 'place_name', 'state_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largo_maximo_zona = data_original.place_with_parent_names.apply(lambda x: len(x[1:len(x) - 1].split(\"|\"))).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_ubicacion(zona_str, largo_maximo_zona):\n",
    "    zona_array = zona_str[1:len(zona_str) - 1].split(\"|\")\n",
    "    largo = len(zona_array)\n",
    "    if largo < largo_maximo_zona:\n",
    "        zona_array.extend(np.full(largo_maximo_zona - largo, zona_array[largo - 1]))\n",
    "    return zona_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zonas_serie = data_original.place_with_parent_names.apply(lambda x: agregar_ubicacion(x, largo_maximo_zona))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(largo_maximo_zona):\n",
    "    data[\"zona\" + str((i + 1))] = zonas_serie.apply(lambda x: x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.lat = np.round(data.lat, 2)\n",
    "#data.lon = np.round(data.lon, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.rooms.isnull().sum())\n",
    "regex = re.compile(\"\\d\\sambientes\", flags = re.IGNORECASE)\n",
    "regexRooms = data[(data.rooms.isnull())].description.apply(lambda x: regex.search(str(x)))\n",
    "resultado = regexRooms.apply(lambda x: np.NaN if x is None else x.group(0).lower().replace(\" ambientes\", \"\").strip()).astype(np.float64)\n",
    "data.loc[resultado.index, \"rooms\"]  = resultado\n",
    "print(data.rooms.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.rooms.isnull().sum())\n",
    "regex = re.compile(\"\\d\\samb\", flags = re.IGNORECASE)\n",
    "regexRooms = data[(data.rooms.isnull())].description.apply(lambda x: regex.search(str(x)))\n",
    "resultado = regexRooms.apply(lambda x: np.NaN if x is None else x.group(0).lower().replace(\" amb\", \"\").strip()).astype(np.float64)\n",
    "data.loc[resultado.index, \"rooms\"]  = resultado\n",
    "print(data.rooms.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.rooms.isnull().sum())\n",
    "regex = re.compile(\"1\\sambiente\", flags = re.IGNORECASE)\n",
    "regexRooms = data[(data.rooms.isnull())].description.apply(lambda x: regex.search(str(x)))\n",
    "resultado = regexRooms.apply(lambda x: np.NaN if x is None else x.group(0).lower().replace(\" ambiente\", \"\").strip()).astype(np.float64)\n",
    "data.loc[resultado.index, \"rooms\"]  = resultado\n",
    "print(data.rooms.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.rooms.isnull().sum())\n",
    "regex = re.compile(\"un\\sambiente\", flags = re.IGNORECASE)\n",
    "regexRooms = data[(data.rooms.isnull())].description.apply(lambda x: regex.search(str(x)))\n",
    "resultado = regexRooms.apply(lambda x: np.NaN if x is None else x.group(0).lower().replace(\"un ambiente\", \"1\").strip()).astype(np.float64)\n",
    "data.loc[resultado.index, \"rooms\"]  = resultado\n",
    "print(data.rooms.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=[\"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimino nulos\n",
    "data = data.dropna()\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data[feature_cols].corr(), center=0, cmap=\"YlGnBu\", annot=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prueba = data_original[data_original.property_type == \"apartment\"].surface_covered_in_m2 / data_original[data_original.property_type == \"apartment\"].rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=[\"rooms\"], prefix=\"rooms_\", drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.get_dummies(data, columns=[\"lat\"], prefix=\"lat_\", drop_first=True)\n",
    "#data = pd.get_dummies(data, columns=[\"lon\"], prefix=\"lon_\", drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(largo_maximo_zona):\n",
    "    data = pd.get_dummies(data, columns=[\"zona\" + str(i + 1)], prefix=\"z\" + str(i + 1) + \"_\", drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = data.columns.values.tolist()\n",
    "feature_cols.remove('price_usd_per_m2')\n",
    "predecir = \"price_usd_per_m2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model_train_test_error_statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train_test_error_statsmodels(df, feature_cols, columna_predecir):\n",
    "    X = df[feature_cols]\n",
    "    y = df[columna_predecir]\n",
    "    X_constant = sm.add_constant(X)\n",
    "    modelo = sm.OLS(y, X_constant).fit()\n",
    "    y_pred = modelo.predict(X_constant)\n",
    "    print (modelo.summary())\n",
    "    print ()\n",
    "    return modelo, y, X_constant, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloOLS, yOLS, X_constant, X = model_train_test_error_statsmodels(\n",
    "    data, \n",
    "    feature_cols, predecir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = modeloOLS.pvalues[modeloOLS.pvalues <= 0.01].index.values[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model_train_test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función recibe el modelo ya instanciado con los hiperparámetros, el dataframe, \n",
    "# los nombres de las columnas predictoras y el nombre de la columna que quiero predecir\n",
    "def model_train_test_error(modelo, df, feature_cols, columna_predecir):\n",
    "    X = df[feature_cols]\n",
    "    y = df[columna_predecir]\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "    modelo_fit = modelo.fit(X_train, y_train)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    #print (feature_cols)\n",
    "    print (\"y_test sample: \",y_test.values[0:10])\n",
    "    print (\"y_pred sample: \",y_pred[0:10].astype(int))\n",
    "    print ('Metrics.MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print ('Metrics.MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
    "    print ('Metrics.RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    print ('Metrics.R2:', metrics.r2_score(y_test, y_pred))\n",
    "    print (\"Modelo_fit.r^2:\", modelo_fit.score(X_test, y_test))    \n",
    "    print ('Modelo_fit.Score test: ', modelo_fit.score(X_test, y_test))\n",
    "    print ('Modelo_fit.Score train: ', modelo_fit.score(X_train, y_train))\n",
    "    #print (\"Modelo_fit.coef: \", modelo_fit.coef_)\n",
    "\n",
    "    if hasattr(modelo, 'alpha_'):    \n",
    "        print(\"Alpha: \", modelo_fit.alpha_)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(y_test, y_pred, edgecolors=(0, 0, 0))\n",
    "    ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\n",
    "    ax.set_xlabel('Measured')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    plt.show()        \n",
    "        \n",
    "    print ()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_test_error(\n",
    "    linear_model.LinearRegression(), \n",
    "    data, \n",
    "    feature_cols, predecir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_test_error(\n",
    "    linear_model.Ridge(alpha=0.5, normalize=True), \n",
    "    data, \n",
    "    feature_cols, predecir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_test_error(\n",
    "    linear_model.Lasso(alpha=0.5, normalize=True), \n",
    "    data, \n",
    "    feature_cols, predecir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_test_error(\n",
    "    linear_model.ElasticNet(alpha=0.5, normalize=True), \n",
    "    data, \n",
    "    feature_cols, predecir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_test_error(\n",
    "    linear_model.RidgeCV(alphas=np.linspace(0.01, 10, 20), cv=3, normalize=True,scoring='r2'), \n",
    "    data, \n",
    "    feature_cols, predecir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_test_error(\n",
    "    linear_model.LassoCV(alphas=np.linspace(0.01, 100, 100), cv=3, normalize=True), \n",
    "    data, \n",
    "    feature_cols, predecir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_test_error(\n",
    "    linear_model.ElasticNetCV(alphas=np.linspace(0.01, 100, 100), cv=3, normalize=True), \n",
    "    data, \n",
    "    feature_cols, predecir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model_train_test_error_CrossVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train_test_error_CrossVal(modelo, df, feature_cols, columna_predecir):\n",
    "    X = df[feature_cols]\n",
    "    y = df[columna_predecir]\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "    modelo_fit = modelo.fit(X_train, y_train)\n",
    "    cv = model_selection.KFold(5, shuffle=False)\n",
    "    scores = model_selection.cross_val_score(modelo, X_train, y_train, cv=cv, scoring='r2')\n",
    "\n",
    "    if hasattr(modelo, 'alpha_'):\n",
    "        print(dict(alpha=modelo.alpha_, scores=scores, mean_score=scores.mean(), zero_coefs=(modelo.coef_ == 0).sum()))\n",
    "    else:\n",
    "        print(\"scores: \", scores)\n",
    "        print(\"media de scores\", scores.mean())\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_test_error_CrossVal(\n",
    "    linear_model.LinearRegression(), \n",
    "    data, \n",
    "    feature_cols, predecir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_test_error_CrossVal(\n",
    "    linear_model.Ridge(normalize=True), \n",
    "    data, \n",
    "    feature_cols, predecir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_test_error_CrossVal(\n",
    "    linear_model.Lasso(normalize=True), \n",
    "    data, \n",
    "    feature_cols, predecir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_test_error_CrossVal(\n",
    "    linear_model.ElasticNet(normalize=True), \n",
    "    data, \n",
    "    feature_cols, predecir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model_train_test_error_CrossValPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train_test_error_CrossValPredict(modelo, df, feature_cols, columna_predecir):\n",
    "    X = df[feature_cols]\n",
    "    y = df[columna_predecir]\n",
    "    predicted = model_selection.cross_val_predict(modelo, X, y, cv=10)\n",
    "    print ('Metrics.R2:', metrics.r2_score(y, predicted))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(y, predicted, edgecolors=(0, 0, 0))\n",
    "    ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\n",
    "    ax.set_xlabel('Measured')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_test_error_CrossValPredict(\n",
    "    linear_model.LinearRegression(), \n",
    "    data, \n",
    "    feature_cols, predecir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_test_error_CrossValPredict(\n",
    "    linear_model.Ridge(normalize=True), \n",
    "    data, \n",
    "    feature_cols, predecir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_test_error_CrossValPredict(\n",
    "    linear_model.Lasso(normalize=True), \n",
    "    data, \n",
    "    feature_cols, predecir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_test_error_CrossValPredict(\n",
    "    linear_model.ElasticNet(normalize=True), \n",
    "    data, \n",
    "    feature_cols, predecir)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Workshop_FB_Regresion_Lineal.ipynb",
   "provenance": [
    {
     "file_id": "1tLnxwf-lAA3so9YuHSq1nl6xxmW9kElL",
     "timestamp": 1544685889886
    },
    {
     "file_id": "1kx27Zo-Ir1nMRVUs6Si_Lz9bKhlP8gy4",
     "timestamp": 1530850462629
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
